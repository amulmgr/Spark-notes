spark-shell â€“master yarn  --num-executors 2
import java.util.Calendar
import org.apache.spark.sql.SparkSession
import spark.implicits._

val format = new java.text.SimpleDateFormat("dd-MM-yyyy")
val date = format.format(new java.util.Date())

val security_data = spark.read.parquet("s3://rfi-rawzone/security-master/" + date + "/*")
security_data.createOrReplaceTempView("security_master")

val sqlDF_security_master = spark.sql("SELECT TICKER,ASSET_CLASS_CODE FROM security_master")

sqlDF.show -- Sample result

+------+----------------+
|TICKER|ASSET_CLASS_CODE|
+------+----------------+
|  RCII|          EQUITY|
|    FN|            BOND|
|    FN|            BOND|
|   AVA|          EQUITY|
|  GIMB|          EQUITY|
|   AIZ|          EQUITY|
|   RBS|            BOND|
|  8303|          EQUITY|
|   KFY|          EQUITY|
|     0|          EQUITY|
|   JLL|          EQUITY|
|     0|            BOND|
|    GN|            BOND|
|    FN|            BOND|
|    FN|            BOND|
|    FN|            BOND|
|    GN|            BOND|
|    G2|            BOND|
|    FN|            BOND|
| SJR/B|          EQUITY|
+------+----------------+



val country = spark.read.parquet("s3://rfi-rawzone/reference-files/Country/*")

country.createOrReplaceTempView("country")

val sqlDF_country = spark.sql("SELECT count(*) from country")

sqlDF_country.show

val country_join = spark.sql("SELECT * from security_master s JOIN country c  where s.Country_Issue = c.COUNTRY_ISO_2")

country_join.saveAsParquetFile("s3://rfi-processed/good-records" + date)



val currency = spark.read.parquet("s3://rfi-rawzone/reference-files/Currency/*")

currency.createOrReplaceTempView("currency")

val sqlDF_currency = spark.sql("SELECT count(*) from currency")

sqlDF_currency.show

val currency_join = spark.sql("SELECT * from security_master s join currency cur  where s.CURRENCY_TRADED = cur.ISO_CCY_CODE")

currency_join.show




val issue_master = spark.read.parquet("s3://rfi-rawzone/reference-files/Issue-Master/*")

issue_master.createOrReplaceTempView("issue_master")

val sqlDF_issue_master = spark.sql("SELECT count(*) from issue_master")

sqlDF_issue_master.show

val issue_master_join = spark.sql("SELECT * from security_master s join issue_master im  where s.ISSUER = im.ISSUER")

issue_master_join.show


-- val final_gooddata = spark.sql("SELECT CADIS_ID,ASSET_CLASS_CODE,BB_EXCH_CODE,CADIS_ID_ISSUER,COUNTRY_INCORPORATION,COUNTRY_ISSUE,CURRENCY_TRADED,CUSIP,CUSIP/ISIN,DATA_QUALITY_IND,INDUSTRY_CODE,ISIN,ISSUE_DATE,NAME_LONG,NAME_SHORT,PRIMARY_EXCHANGE,PRIMARY_SECURITY_TICKER,SEC_TYP_BB,SEC_TYP2_BB,SEDOL,TICKER,TICKER_BB,CURRENCY_SETTLEMENT from security_master s JOIN country c JOIN currency cur JOIN issue_master im  where s.Country_Issue = c.COUNTRY_ISO_2 and s.CURRENCY_TRADED = cur.ISO_CCY_CODE and s.ISSUER = im.ISSUER")

val gooddata = spark.sql("SELECT s.* from security_master s JOIN country c JOIN currency cur JOIN issue_master im  where s.Country_Issue = c.COUNTRY_ISO_2 and s.CURRENCY_TRADED = cur.ISO_CCY_CODE and s.CADIS_ID_ISSUER = im.CADIS_ID_ISSUER")

gooddata.createOrReplaceTempView("data_filtered_good_table")

val get_res = spark.sql("select CADIS_ID_ISSUER from data_filtered_good_table where CADIS_ID_ISSUER = '1744'")

val final_baddata = security_data.except(gooddata)

final_baddata.createOrReplaceTempView("final_bad_table")

val final_gooddata = spark.sql("SELECT sm.CADIS_ID, sm.ASSET_CLASS_CODE, sm.BB_EXCH_CODE, sm.CADIS_ID_ISSUER, sm.COUNTRY_INCORPORATION, sm.COUNTRY_ISSUE, cou.COUNTRY_NAME as COUNTRY_ISSUE_DESC, sm.CURRENCY_TRADED, cur.ISO_DESCRIPTION as CURRENCY_TRADED_DESC, sm.CUSIP, sm.CUSIP/ISIN,sm.DATA_QUALITY_IND, sm.INDUSTRY_CODE, sm.ISIN, sm.ISSUE_DATE, iss.LONG_NAME as ISSUER_LONG_NAME, iss.SHORT_NAME as ISSUER_SHORT_NAME, sm.PRIMARY_EXCHANGE, sm.PRIMARY_SECURITY_TICKER, sm.SEC_TYP_BB, sm.SEC_TYP2_BB, sm.SEDOL, sm.TICKER, sm.TICKER_BB, sm.CURRENCY_SETTLEMENT from data_filtered_good_table sm JOIN country cou JOIN currency cur JOIN issue_master iss  WHERE iss.CADIS_ID_ISSUER = sm.CADIS_ID_ISSUER and cou.COUNTRY_ISO_2  = sm.COUNTRY_ISSUE and sm.CURRENCY_TRADED = cur.ISO_CCY_CODE")


final_gooddata.write.format("com.databricks.spark.csv").option("header","true").save("s3://rfi-curatedzone/security-master/good-records/"+date)

final_baddata.write.format("com.databricks.spark.csv").option("header","true").save("s3://rfi-curatedzone/security-master/bad-records/"+date)

issue_master.write.format("com.databricks.spark.csv").option("header","true").save("s3://rfi-curatedzone/issue-master")

country.write.format("com.databricks.spark.csv").option("header","true").save("s3://rfi-curatedzone/country")

currency.write.format("com.databricks.spark.csv").option("header","true").save("s3://rfi-curatedzone/currency")







